{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf6ecbe5",
   "metadata": {},
   "source": [
    "library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c7965572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce2d22a",
   "metadata": {},
   "source": [
    "parameter & utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2ddf034d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--sampling_frequency',type=int, default=20000)\n",
    "parser.add_argument('--lr_length',type=int, default=1000, help='length of low-resolution signal')\n",
    "parser.add_argument('--hr_length',type=int, default=10000)\n",
    "parser.add_argument('--train_x_img_dir',type=str, default='./data/train/x')\n",
    "parser.add_argument('--train_y_img_dir',type=str, default='./data/train/y')\n",
    "parser.add_argument('--test_x_img_dir',type=str, default='./data/test/x')\n",
    "parser.add_argument('--test_y_img_dir',type=str, default='./data/test/y')\n",
    "parser.add_argument('--valid_x_img_dir',type=str, default='./data/valid/x')\n",
    "parser.add_argument('--valid_y_img_dir',type=str, default='./data/valid/y')\n",
    "parser.add_argument('--n_samples',type=int, default=100)\n",
    "parser.add_argument('--patch_size',type=int, default=128)\n",
    "parser.add_argument('--stride',type=int, default=96)\n",
    "\n",
    "parser.add_argument('--epochs',type=int, default=50)\n",
    "parser.add_argument('--lr',type=float, default=1e-4)\n",
    "parser.add_argument('--early_stop',type=int, default=20, help='early stop_patience')\n",
    "parser.add_argument('--batch_size',type=int, default=16)\n",
    "#parser.add_argument('--train_random_seed',type=int, default=42)\n",
    "#parser.add_argument('--test_random_seed',type=int, default=43)\n",
    "\n",
    "opt = parser.parse_args('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fff2f53",
   "metadata": {},
   "source": [
    "data preprocssing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "cf3ea7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFTProcessor():\n",
    "    \n",
    "    '''signal to FFT image'''\n",
    "    \n",
    "    def __init__(self, sampling_frequency, img_x_dir, img_y_dir):\n",
    "        self.fs = sampling_frequency\n",
    "        self.img_x_dir = img_x_dir\n",
    "        self.img_y_dir = img_y_dir\n",
    "        #self.random_seed = random_seed\n",
    "        \n",
    "    def generate_random_signal(self, length):\n",
    "        t = np.linspace(0, length, int(self.fs), endpoint=False)\n",
    "        x = np.zeros_like(t)\n",
    "        \n",
    "        num_components = np.random.randint(20, 50)  # 2~4\n",
    "        for _ in range(num_components):\n",
    "            A = np.random.uniform(0.5, 3.0)            # 진폭\n",
    "            f = np.random.uniform(1, 20)               # 주파수 (Hz)\n",
    "            phi = np.random.uniform(0, 2*np.pi)        # 위상\n",
    "            x += A * np.sin(2 * np.pi * f * t + phi)\n",
    "        return x\n",
    "\n",
    "    def process_batch(self, n_samples, patch_size, stride):\n",
    "        for sample_idx in range(n_samples):\n",
    "            #np.random.seed(self.random_seed)\n",
    "            x = self.generate_random_signal(opt.lr_length)  # 이렇게 opt. 쓰는 것?? 별론가\n",
    "            y = self.generate_random_signal(opt.hr_length)\n",
    "\n",
    "            X = np.fft.fft(x)\n",
    "            Y = np.fft.fft(y)\n",
    "            freqs = np.fft.fftfreq(len(X), d=1/self.fs)\n",
    "            mag_X = np.abs(X)* 2 / len(X)\n",
    "            mag_Y = np.abs(Y)* 2 / len(Y)\n",
    "\n",
    "        \n",
    "            half = int(len(X)/2)\n",
    "            freq_mag_X = np.column_stack((freqs[:half], mag_X[:half]))\n",
    "            freq_mag_Y = np.column_stack((freqs[:half], mag_Y[:half]))\n",
    "            \n",
    "            save_img(freq_mag_X, self.img_x_dir, sample_idx)\n",
    "            save_img(freq_mag_Y, self.img_y_dir, sample_idx)\n",
    "            \n",
    "            save_patch(f\"{self.img_x_dir}/fft_{sample_idx:03d}.png\", self.img_x_dir, sample_idx, patch_size, stride)\n",
    "            save_patch(f\"{self.img_y_dir}/fft_{sample_idx:03d}.png\", self.img_y_dir, sample_idx, patch_size, stride)\n",
    "\n",
    "\n",
    "def save_img(x, img_dir, idx):\n",
    "    \n",
    "    plt.plot(x[:, 0], x[:, 1])\n",
    "    plt.axis('off')     # 축 숨기기 (x, y 모두)\n",
    "    plt.gca().spines['top'].set_visible(False)    # 테두리(스파인) 숨기기\n",
    "    plt.gca().spines['right'].set_visible(False)\n",
    "    plt.gca().spines['bottom'].set_visible(False)\n",
    "    plt.gca().spines['left'].set_visible(False)\n",
    "    plt.savefig(f\"{img_dir}/fft_{idx:03d}.png\", bbox_inches = 'tight', transparent = True)\n",
    "    plt.close()\n",
    "    \n",
    "def save_patch(x, img_dir, sample_idx, patch_size, stride):\n",
    "    patch_idx = 0\n",
    "    img = Image.open(x)\n",
    "    img = np.array(img)\n",
    "    for i in range(0, img.shape[0] - patch_size + 1, stride):\n",
    "        for j in range(0, img.shape[1] - patch_size + 1, stride):\n",
    "            patch = img[i:i+patch_size, j:j+patch_size]\n",
    "            plt.imsave(f\"{img_dir}/fft_{sample_idx:03d}_{patch_idx:02d}.png\", patch, cmap='gray')\n",
    "            patch_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "02af5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "FFTProcessor(opt.sampling_frequency, opt.train_x_img_dir, opt.train_y_img_dir).process_batch(opt.n_samples, opt.patch_size, opt.stride)\n",
    "FFTProcessor(opt.sampling_frequency, opt.test_x_img_dir, opt.test_y_img_dir).process_batch(opt.n_samples, opt.patch_size, opt.stride)\n",
    "FFTProcessor(opt.sampling_frequency, opt.valid_x_img_dir, opt.valid_y_img_dir).process_batch(opt.n_samples, opt.patch_size, opt.stride)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4184e18d",
   "metadata": {},
   "source": [
    "data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "32f00ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class make_dataset():\n",
    "    def __init__(self, train_x, train_y, test_x, test_y, valid_x, valid_y):\n",
    "        self.train_x = train_x\n",
    "        self.train_y = train_y\n",
    "        self.test_x = test_x\n",
    "        self.test_y = test_y\n",
    "        self.valid_x = valid_x\n",
    "        self.valid_y = valid_y\n",
    "        \n",
    "    def main(self):\n",
    "        self.to_tensor()\n",
    "        return self.train_dl, self.test_dl, self.valid_dl\n",
    "                \n",
    "    def to_tensor(self):\n",
    "        # To tensor\n",
    "        train_x = torch.tensor(self.train_x)\n",
    "        train_y = torch.tensor(self.train_y)\n",
    "        test_x = torch.tensor(self.test_x)\n",
    "        test_y = torch.tensor(self.test_y)\n",
    "        valid_x = torch.tensor(self.valid_x)\n",
    "        valid_y = torch.tensor(self.valid_y)\n",
    "\n",
    "        train = MyDataset(train_x, train_y)\n",
    "        test = MyDataset(test_x, test_y)\n",
    "        valid = MyDataset(valid_x, valid_y)\n",
    "\n",
    "        self.train_dl = DataLoader(train, opt.batch_size, shuffle=True)\n",
    "        self.test_dl = DataLoader(test, opt.batch_size, shuffle=False)\n",
    "        self.valid_dl = DataLoader(valid, opt.batch_size, shuffle=False)\n",
    "    \n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x.float()\n",
    "        self.y = y.float()\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = self.x[idx]  # [H, W]\n",
    "        y = self.y[idx]\n",
    "        x = x.unsqueeze(0)  # → [1, H, W]\n",
    "        y = y.unsqueeze(0)\n",
    "        \n",
    "        return x.to(device), y.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "52336b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = []\n",
    "for filename in os.listdir('./data/train/x'):\n",
    "    if filename.count('_') != 1:\n",
    "    #if filename.count('_') == 1:\n",
    "        filename = filename\n",
    "        img_path = os.path.join('./data/train/x', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        train_x.append(img_array)\n",
    "    \n",
    "train_y = []\n",
    "for filename in os.listdir('./data/train/y'):\n",
    "    if filename.count('_') != 1:\n",
    "        filename = filename\n",
    "        img_path = os.path.join('./data/train/y', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        train_y.append(img_array)\n",
    "    \n",
    "test_x = []\n",
    "for filename in os.listdir('./data/test/x'):\n",
    "    if filename.count('_') != 1:\n",
    "    #if filename.count('_') == 1:\n",
    "        filename = filename\n",
    "        img_path = os.path.join('./data/test/x', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        test_x.append(img_array)\n",
    "    \n",
    "test_y = []\n",
    "for filename in os.listdir('./data/test/y'):\n",
    "    if filename.count('_') != 1:\n",
    "        img_path = os.path.join('./data/test/y', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        test_y.append(img_array)\n",
    "\n",
    "valid_x = []\n",
    "for filename in os.listdir('./data/valid/x'):\n",
    "    if filename.count('_') != 1:\n",
    "    #if filename.count('_') == 1:\n",
    "        filename = filename\n",
    "        img_path = os.path.join('./data/valid/x', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        valid_x.append(img_array)\n",
    "    \n",
    "valid_y = []\n",
    "for filename in os.listdir('./data/valid/y'):\n",
    "    if filename.count('_') != 1:\n",
    "        img_path = os.path.join('./data/valid/y', filename)\n",
    "        img = Image.open(img_path).convert('L')\n",
    "        img_array = np.array(img)\n",
    "        valid_y.append(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "7b11b8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl, test_dl, valid_dl = make_dataset(train_x, train_y, test_x, test_y, valid_x, valid_y).main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861fb37e",
   "metadata": {},
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "59d9ce77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRCNN(nn.Module):\n",
    "    def __init__(self, num_channels=1): #흑백\n",
    "        super(SRCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_channels, 64, kernel_size=9, padding = 9//2) #(H, W) \n",
    "        self.conv2 = nn.Conv2d(64, 32, kernel_size=5, padding = 5//2)\n",
    "        self.conv3 = nn.Conv2d(32, num_channels, kernel_size=5, padding = 5//2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x=self.relu(self.conv1(x))\n",
    "        x=self.relu(self.conv2(x))\n",
    "        x=self.conv3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6765fa5",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "5ef1a334",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dl, valid_dl, optimizer, loss_fn, device, num_epochs):\n",
    "    model = model.to(device)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "        train_bar = tqdm(train_dl, desc=\"Training\", leave=False)\n",
    "\n",
    "        for inputs, targets in train_bar:\n",
    "            inputs = inputs.to(device).float()\n",
    "            targets = targets.to(device).float()\n",
    "\n",
    "            # Forward\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "\n",
    "            # Backward\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = total_loss / len(train_dl)\n",
    "        print(f\"Train Loss: {avg_train_loss:.4f}\")\n",
    "\n",
    "        # Validation\n",
    "        if valid_dl:\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            val_bar = tqdm(valid_dl, desc=\"Validating\", leave=False)\n",
    "            with torch.no_grad():\n",
    "                for inputs, targets in val_bar:\n",
    "                    inputs = inputs.to(device)\n",
    "                    targets = targets.to(device)\n",
    "\n",
    "                    outputs = model(inputs)\n",
    "                    loss = loss_fn(outputs, targets)\n",
    "                    val_loss += loss.item()\n",
    "                    val_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "            avg_val_loss = val_loss / len(valid_dl)\n",
    "            print(f\"Valid Loss: {avg_val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ade942",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SRCNN()\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "train(model, train_dl, valid_dl, optimizer, loss_fn, device, opt.epochs)\n",
    "#3669/1947 -> 1947/1920 (epoch 50): 별 의미 x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a097981",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "8a87ecce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_dl, device, loss_fn):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    total_loss = 0\n",
    "    n = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_dl:\n",
    "            inputs = inputs.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "            n += inputs.size(0)\n",
    "            \n",
    "    print(f\"total loss: {total_loss/n:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "7eafa49a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total loss: 3826.01\n"
     ]
    }
   ],
   "source": [
    "model = SRCNN()\n",
    "#model.load_state_dict(torch.load('best.pth', map_location='cpu'))\n",
    "\n",
    "test(model, test_dl, device, loss_fn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "superi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
